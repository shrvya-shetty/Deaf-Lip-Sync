# Deaf-Lip-Sync

**WATCH OUT MY OWN COLLECTED DATASET :**  https://github.com/shrvya-shetty/Lip-Reading-DataSet
## AboutðŸ”¸
Deaf-Lip-Sync is a project aimed at developing a system to assist the hearing impaired by translating lip movements into text. This project involves training a machine learning model to recognize and interpret lip movements from video input and convert them into corresponding text.

## Features
  1) Machine Learning Model: Utilizes a trained model to interpret lip movements.
  2) Web Application: Frontend interface for users to interact with the system.
  3) Training Data: Includes datasets used for training the model.
     
<div style="display: flex;">
    <div style="margin-right: 10px;">
        <img src="https://raw.githubusercontent.com/shrvya-shetty/Deaf-Lip-Sync/main/Shravya's%20Demo/img1.png" alt="Taling  image" style="width: 200px; height: 300px;">
              <img src="https://raw.githubusercontent.com/shrvya-shetty/Deaf-Lip-Sync/main/Shravya's%20Demo/img2.png" alt="Non Talking image" style="width: 200px; height: 300px;">
                            <img src="https://raw.githubusercontent.com/shrvya-shetty/Deaf-Lip-Sync/main/Shravya's%20Demo/bye.png" alt="Predicted image" style="width: 200px; height: 300px;">


    
</div>





## Directory Structure
   1) _**app.py**_: âž¡ Main application script.
   2) _**constants1.py**_: âž¡ Contains constants used in the project.
   3) _**training/**_: âž¡ Directory containing training scripts and data.
   4) _**static/**:_  âž¡ Static files for the web application.
   5) _**templates/**:_  âž¡ HTML templates for the web application.
   6) _**README.md**:_  âž¡ Project documentation.
   7) _**first phase report (2).pdf**:_  âž¡ Initial project report.

## Contributing
Contributions are welcome! Please submit a pull request or open an issue for any improvements or bug fixes. Contact at shravyashetty159@gmail.com
